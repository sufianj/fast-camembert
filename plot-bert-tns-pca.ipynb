{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e72bf504-bb7b-4fe2-9c9d-9078a01054b7",
   "metadata": {},
   "source": [
    "### another BERT embeddings visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661b1d9-e413-4509-9e27-9fa80949e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install livelossplot\n",
    "#!pip install emoji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d49857c-7913-4688-866d-ad4b397f4548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 16 16:34:06 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 471.41       Driver Version: 471.41       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 98%   47C    P2   307W / 450W |   6183MiB / 24576MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1280    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      2648    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      6024      C   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      6632    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      6644    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      8340    C+G   Insufficient Permissions        N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55abfae8-f401-4beb-99a0-0edeb30d09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from transformers import BertForSequenceClassification,BertTokenizerFast,AdamW,logging\n",
    "import torch\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "pd.options.display.max_colwidth = 1000\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "import re,emoji\n",
    "import imageio,glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb50c3fd-c309-43ee-b172-3be7d1d56766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer, CamembertModel, CamembertConfig, CamembertForSequenceClassification, CamembertForMultipleChoice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab814a2a-9891-4236-b800-e5429b6b3f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# manually seed RNGs for reproducibility of your results\n",
    "torch.manual_seed(1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c127e2-7aa6-424e-acbc-ae3391433191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'test' nÔøΩest pas reconnu en tant que commande interne\n",
      "ou externe, un programme exÔøΩcutable ou un fichier de commandes.\n",
      "Cloning into '/tmp/tweeteval'...\n"
     ]
    }
   ],
   "source": [
    "!test -d /tmp/tweeteval || git clone https://github.com/cardiffnlp/tweeteval /tmp/tweeteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba51d53-9067-4696-8352-78cf2a43f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(text_path,label_path):\n",
    "    with open(text_path,'rt') as fi:\n",
    "        texts = fi.read().strip().split('\\n')\n",
    "    text_dfs = pd.Series(data=texts,name='text',dtype='str')\n",
    "    labels_dfs = pd.read_csv(label_path,names=['label'],index_col=False).label\n",
    "    ret_df = pd.concat([text_dfs,labels_dfs],axis=1)\n",
    "    return ret_df\n",
    "\n",
    "train_df = load_df('/tmp/tweeteval/datasets/hate/train_text.txt','/tmp/tweeteval/datasets/hate/train_labels.txt').head(1500)\n",
    "val_df = load_df('/tmp/tweeteval/datasets/hate/val_text.txt','/tmp/tweeteval/datasets/hate/val_labels.txt').head(1500)\n",
    "test_df = load_df('/tmp/tweeteval/datasets/hate/test_text.txt','/tmp/tweeteval/datasets/hate/test_labels.txt').head(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de28217-b38e-4f7f-9a79-f999014fd40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user nice new signage. Are you not concerned by Beatlemania -style hysterical crowds crongregating on you‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman who you fucked multiple times saying yo dick small is a compliment you know u hit that spot üòé</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user real talk do you have eyes or were they gouged out by a rapefugee?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your girlfriend lookin at me like a groupie in this bitch!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hysterical woman like @user</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           text  label\n",
       "0  @user nice new signage. Are you not concerned by Beatlemania -style hysterical crowds crongregating on you‚Ä¶       0\n",
       "1        A woman who you fucked multiple times saying yo dick small is a compliment you know u hit that spot üòé       1\n",
       "2                               @user @user real talk do you have eyes or were they gouged out by a rapefugee?       1\n",
       "3                                                   your girlfriend lookin at me like a groupie in this bitch!       1\n",
       "4                                                                                  Hysterical woman like @user       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a1e5f6-5ca2-4ba2-ada0-bc62fed1175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_urls(row):\n",
    "    row.text = re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?¬´¬ª‚Äú‚Äù‚Äò‚Äô]))\",\"HTTPURL\", row.text)\n",
    "    return row\n",
    "\n",
    "def encode_mentions_hashtags(row):\n",
    "    row.text = row.text.replace('@',' @')\n",
    "    row.text = re.sub(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)\",\"@USER\", row.text)\n",
    "    row.text = row.text.replace('#',' ')\n",
    "    return row\n",
    "\n",
    "def encode_emojis(row):\n",
    "    row.text = emoji.demojize(row.text)\n",
    "    return row\n",
    "\n",
    "def remove_extra_spaces(row):\n",
    "    row.text = ' '.join(row.text.split())\n",
    "    return row\n",
    "\n",
    "def lower_text(row):\n",
    "    row.text = row.text.lower()\n",
    "    return row\n",
    "\n",
    "def preprocess_data_df(df):\n",
    "    df = df.apply(encode_urls,axis=1)\n",
    "    df = df.apply(encode_mentions_hashtags,axis=1)\n",
    "    df = df.apply(encode_emojis,axis=1)\n",
    "    df = df.apply(remove_extra_spaces,axis=1)\n",
    "    df = df.apply(lower_text,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba535e2e-ffd7-43f7-b9e9-72cdb07220d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess_data_df(train_df)\n",
    "val_df = preprocess_data_df(val_df)\n",
    "test_df = preprocess_data_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdaa4fb2-0656-4d4a-ba56-6312abcb683f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513e89dff19f46edaae6b14f348e1fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "def get_bert_encoded_data_in_batches(df,batch_size = 0,max_seq_length = 50):\n",
    "    global tokenizer\n",
    "    data = [(row.text,row.label,) for _,row in df.iterrows()]\n",
    "    sampler = torch.utils.data.sampler.SequentialSampler(data)\n",
    "    batch_sampler = torch.utils.data.BatchSampler(sampler,batch_size=batch_size if batch_size > 0 else len(data), drop_last=False)\n",
    "    for batch in batch_sampler:\n",
    "        encoded_batch_data = tokenizer.batch_encode_plus([data[i][0] for i in batch],max_length = max_seq_length,pad_to_max_length=True,truncation=True)\n",
    "        seq = torch.tensor(encoded_batch_data['input_ids'])\n",
    "        mask = torch.tensor(encoded_batch_data['attention_mask'])\n",
    "        yield (seq,mask),torch.LongTensor([data[i][1] for i in batch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70888aee-b407-4acd-9672-5fa69b753011",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_cmb_model = CamembertModel.from_pretrained(\"model/model_out\", output_attentions=True,  output_hidden_states=True)\n",
    "ft_cmb_tokenizer = CamembertTokenizer.from_pretrained(\"model/model_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f20c92b-f13a-46ef-8734-60fbb59824b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_cls_model5 =  CamembertForSequenceClassification.from_pretrained(\"twt_cls_model5/model_out\", output_attentions=True,  output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7134425f-8771-4401-8df6-686b7e4a6631",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_b = \"les pontes commencent d'√™tre d√©pos√©es sur ma√Øs grain en zones pr√©coces et le seuil d'intervention sera atteint prochainement.\"\n",
    "sentence_a = \"En raison des fortes temp√©ratures de ces derniers jours, le vol s'est nettement intensifi√© et sera tr√®s group√©.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35d84d15-3e37-48e4-aec3-0aa77bf7b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ft_cmb_tokenizer.encode_plus(sentence_a, None, return_tensors='pt', add_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "86bb3070-c298-4116-8b09-a1db8c6ffcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ids = inputs['input_ids']\n",
    "cls_embeddings, cls_hidden_states, cls_all_layer_embeddings = twt_cls_model5(input_ids)\n",
    "\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "tokens = ft_cmb_tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "ft_all_layer_embeddings = ft_cmb_model(input_ids)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "58d5df0c-4fbe-4317-8881-ee8ac8f67ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9162255e-5489-444d-ac5e-2b0847e0fb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 25, 25])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads\n",
    "#Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).\n",
    "cls_all_layer_embeddings[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b13dff5b-8964-4ae3-880d-1f6a5412c151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logits (torch.FloatTensor of shape (batch_size, config.num_labels)) ‚Äì Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "cls_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e768acbf-1a4e-4245-ad3f-e2dd0f89f0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25, 768])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuple of torch.FloatTensor (one for the output of the embeddings + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).\n",
    "#Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "cls_hidden_states[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c686f59-54e5-4d19-80bf-63ba2a5b4bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41974961-be42-44da-ada3-1b709069f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "LEARNING_RATE = 0.00005 #@param [1e-5,5e-5,1e-4] {type:\"raw\"}\n",
    "BATCH_SIZE = 16 #@param [8,16,32,64] {type:\"raw\"}\n",
    "MAX_SEQ_LEN = 50   #@param [50,100,512] {type:\"raw\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e030cb40-f80e-418e-b5cd-686899f8962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reducer = TSNE(n_components=2)\n",
    "#dim_reducer = PCA(n_components=2)\n",
    "\n",
    "def visualize_layerwise_embeddings(hidden_states,masks,ys,title,layers_to_visualize=[0,1,2,3,8,9,10,11]):\n",
    "    global dim_reducer\n",
    "    !mkdir -p /tmp/plots/{title}\n",
    "    num_layers = len(layers_to_visualize)\n",
    "    fig = plt.figure(figsize=(24,(num_layers/4)*6)) #each subplot of size 6x6\n",
    "    ax = [fig.add_subplot(num_layers/4,4,i+1) for i in range(num_layers)]\n",
    "    ys = ys.numpy().reshape(-1)\n",
    "    for i,layer_i in enumerate(layers_to_visualize):#range(hidden_states):\n",
    "        layer_hidden_states = hidden_states[layer_i]\n",
    "        averaged_layer_hidden_states = torch.div(layer_hidden_states.sum(dim=1),masks.sum(dim=1,keepdim=True))\n",
    "        layer_dim_reduced_vectors = dim_reducer.fit_transform(averaged_layer_hidden_states.numpy())\n",
    "        df = pd.DataFrame.from_dict({'x':layer_dim_reduced_vectors[:,0],'y':layer_dim_reduced_vectors[:,1],'label':ys})\n",
    "        df.label = df.label.astype(int)\n",
    "        sns.scatterplot(data=df,x='x',y='y',hue='label',ax=ax[i])\n",
    "        ax[i].set_title(f\"layer {layer_i+1}\")\n",
    "    plt.savefig(f'plots/{title}',format='png',pad_inches=0)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a44663-24a1-4dec-b60b-09de5066874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layerwise_embeddings(cls_hidden_states, cls_all_layer_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add28df3-9e37-446d-aed4-1b99f8e20f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3659dab-24d4-442f-8700-4b43bf0c8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loss_function = torch.nn.NLLLoss()\n",
    "optimizer = AdamW(lr=LEARNING_RATE,params=model.parameters())\n",
    "liveloss = PlotLosses()\n",
    "for epoch in range(EPOCHS+1):\n",
    "\n",
    "    model.train(False)  #toggle model in eval mode\n",
    "    with torch.no_grad():\n",
    "        train_correct_preds,train_total_preds,train_total_loss = 0,0,0.0\n",
    "        train_masks,train_ys = torch.zeros(0,MAX_SEQ_LEN),torch.zeros(0,1)\n",
    "        train_hidden_states = None\n",
    "        for x,y in get_bert_encoded_data_in_batches(train_df,BATCH_SIZE,MAX_SEQ_LEN):\n",
    "            sent_ids,masks = x\n",
    "            sent_ids = sent_ids.to(device)\n",
    "            masks = masks.to(device)\n",
    "            y = y.to(device)\n",
    "            model_out = model(sent_ids,masks,output_hidden_states=True,return_dict=True)\n",
    "            log_probs = torch.nn.functional.log_softmax(model_out.logits, dim=1)\n",
    "            loss = loss_function(log_probs, y)\n",
    "            hidden_states = model_out.hidden_states[1:]\n",
    "            \n",
    "            train_total_loss += (loss.detach() * y.shape[0])\n",
    "            train_preds = torch.argmax(log_probs,dim=1)\n",
    "            train_correct_preds += (train_preds == y).float().sum()\n",
    "            train_total_preds += train_preds.shape[0]\n",
    "\n",
    "            train_masks = torch.cat([train_masks,masks.cpu()])\n",
    "            train_ys = torch.cat([train_ys,y.cpu().view(-1,1)])\n",
    "\n",
    "            if type(train_hidden_states) == type(None):\n",
    "                train_hidden_states = tuple(layer_hidden_states.cpu() for layer_hidden_states in hidden_states)\n",
    "            else:\n",
    "                train_hidden_states = tuple(torch.cat([layer_hidden_state_all,layer_hidden_state_batch.cpu()])for layer_hidden_state_all,layer_hidden_state_batch in zip(train_hidden_states,hidden_states))\n",
    "        \n",
    "        visualize_layerwise_embeddings(train_hidden_states,train_masks,train_ys,epoch,'train_data')\n",
    "\n",
    "        train_acc = train_correct_preds.float() / train_total_preds\n",
    "        train_loss = train_total_loss / train_total_preds\n",
    "        logs['loss'] = train_loss.item()\n",
    "        logs['acc'] = train_acc.item()\n",
    "        #\n",
    "        val_correct_preds,val_total_preds,val_total_loss = 0,0,0.0\n",
    "        val_masks,val_ys = torch.zeros(0,MAX_SEQ_LEN),torch.zeros(0,1)\n",
    "        val_hidden_states = None\n",
    "        for x,y in get_bert_encoded_data_in_batches(val_df,BATCH_SIZE,MAX_SEQ_LEN):\n",
    "            sent_ids,masks = x\n",
    "            sent_ids = sent_ids.to(device)\n",
    "            masks = masks.to(device)\n",
    "            y = y.to(device)\n",
    "            model_out = model(sent_ids,masks,output_hidden_states=True,return_dict=True)\n",
    "            log_probs = torch.nn.functional.log_softmax(model_out.logits, dim=1)\n",
    "            loss = loss_function(log_probs, y)\n",
    "            hidden_states = model_out.hidden_states[1:]\n",
    "            #logging logic\n",
    "            val_total_loss += (loss.detach() * y.shape[0])\n",
    "            val_preds = torch.argmax(log_probs,dim=1)\n",
    "            val_correct_preds += (val_preds == y).float().sum()\n",
    "            val_total_preds += val_preds.shape[0]\n",
    "\n",
    "            val_masks = torch.cat([val_masks,masks.cpu()])\n",
    "            val_ys = torch.cat([val_ys,y.cpu().view(-1,1)])\n",
    "\n",
    "            if type(val_hidden_states) == type(None):\n",
    "                val_hidden_states = tuple(layer_hidden_states.cpu() for layer_hidden_states in hidden_states)\n",
    "            else:\n",
    "                val_hidden_states = tuple(torch.cat([layer_hidden_state_all,layer_hidden_state_batch.cpu()])for layer_hidden_state_all,layer_hidden_state_batch in zip(val_hidden_states,hidden_states))\n",
    "        \n",
    "        visualize_layerwise_embeddings(val_hidden_states,val_masks,val_ys,epoch,'val_data')\n",
    "        val_acc = val_correct_preds.float() / val_total_preds\n",
    "        val_loss = val_total_loss / val_total_preds\n",
    "        logs['val_loss'] = val_loss.item()\n",
    "        logs['val_acc'] = val_acc.item()\n",
    "    if epoch:   #no need to learning-curve plot on 0th epoch\n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139b359-f443-45e4-8e4f-f2bde878bd07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
